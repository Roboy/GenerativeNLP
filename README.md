# Trained models with Seq2Seq NLP

### Twitter chat
- vocab_size 100000
- layer_size 128
- layers_num 4